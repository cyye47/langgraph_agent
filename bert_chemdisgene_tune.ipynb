{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21485388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaoyangye/Documents/Computation/langgraph_agent/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/chaoyangye/Documents/Computation/langgraph_agent/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52f6f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ChemDisGene dataset\n",
    "ds = load_dataset(\"bigbio/chem_dis_gene\", \"chem_dis_gene_bigbio_kb\", trust_remote_code = True)\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc4f0a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relation types:\n",
      "- chem_disease:marker/mechanism\n",
      "- chem_disease:therapeutic\n",
      "- chem_gene:affects^activity\n",
      "- chem_gene:affects^binding\n",
      "- chem_gene:affects^expression\n",
      "- chem_gene:affects^localization\n",
      "- chem_gene:affects^metabolic_processing\n",
      "- chem_gene:affects^transport\n",
      "- chem_gene:decreases^activity\n",
      "- chem_gene:decreases^expression\n",
      "- chem_gene:decreases^metabolic_processing\n",
      "- chem_gene:decreases^transport\n",
      "- chem_gene:increases^activity\n",
      "- chem_gene:increases^expression\n",
      "- chem_gene:increases^metabolic_processing\n",
      "- chem_gene:increases^transport\n",
      "- gene_disease:marker/mechanism\n",
      "- gene_disease:therapeutic\n",
      "- no_relation\n"
     ]
    }
   ],
   "source": [
    "# find all the unique relation labels\n",
    "all_relation_types = set()\n",
    "\n",
    "for doc in ds[\"train\"]:\n",
    "        for rel in doc[\"relations\"]:\n",
    "            all_relation_types.add(rel[\"type\"])\n",
    "\n",
    "# Step 3: Add 'no_relation' for negative examples\n",
    "all_relation_types.add(\"no_relation\")\n",
    "\n",
    "# Step 4: Print them\n",
    "print(\"Unique relation types:\")\n",
    "for rel_type in sorted(all_relation_types):\n",
    "    print(f\"- {rel_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d80fb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label-to-id mapping\n",
    "label2id = {label: idx for idx, label in enumerate(sorted(all_relation_types))}\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c84eb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test\n",
    "if \"test\" not in ds:\n",
    "    ds_split = ds[\"train\"].train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46284f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "    num_rows: 470\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_split[\"train\"] # 9:1 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21570ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build examples from entity pairs\n",
    "def prepare_examples(split):\n",
    "    examples = []\n",
    "    for doc in ds_split[split]:\n",
    "        text = \" \".join(p[\"text\"][0] for p in doc[\"passages\"])\n",
    "        entity_map = {e[\"id\"]: e for e in doc[\"entities\"]}\n",
    "        existing_pairs = {(r[\"arg1_id\"], r[\"arg2_id\"]): r[\"type\"] for r in doc[\"relations\"]}\n",
    "\n",
    "        # Create all possible entity pairs (for binary classification setup)\n",
    "        for e1 in doc[\"entities\"]:\n",
    "            for e2 in doc[\"entities\"]:\n",
    "                if e1[\"id\"] == e2[\"id\"]:\n",
    "                    continue\n",
    "                label = existing_pairs.get((e1[\"id\"], e2[\"id\"]), \"no_relation\")\n",
    "                input_text = f\"{text} [SEP] {e1['text'][0]} [SEP] {e2['text'][0]}\"\n",
    "                examples.append({\n",
    "                    \"text\": input_text,\n",
    "                    \"label\": label2id[label]\n",
    "                })\n",
    "    return Dataset.from_list(examples)\n",
    "\n",
    "train_dataset = prepare_examples(\"train\")\n",
    "test_dataset = prepare_examples(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2784794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]\n",
    "len(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e027b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize\n",
    "def tokenize(example):\n",
    "    encoding = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "    encoding[\"labels\"] = example[\"label\"]\n",
    "    return encoding\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize, batched=False)\n",
    "tokenized_test = test_dataset.map(tokenize, batched=False)\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train!\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function\n",
    "\n",
    "def predict_relation(text: str, entity1: str, entity2: str, model, tokenizer, id2label):\n",
    "    \"\"\"\n",
    "    Predict the relation between two entities in a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input sentence or passage.\n",
    "        entity1 (str): The first entity.\n",
    "        entity2 (str): The second entity.\n",
    "        model: The fine-tuned BERT-based model.\n",
    "        tokenizer: The tokenizer used during training.\n",
    "        id2label (dict): A dictionary mapping label IDs to relation strings.\n",
    "\n",
    "    Returns:\n",
    "        predicted_label (str): The predicted relation type.\n",
    "        confidence (float): The confidence score of the prediction.\n",
    "    \"\"\"\n",
    "    # Format the input the same way you did during training\n",
    "    input_text = f\"{text} [SEP] {entity1} [SEP] {entity2}\"\n",
    "\n",
    "    # Tokenize and encode\n",
    "    encoding = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    # Move to the same device as the model\n",
    "    encoding = {k: v.to(model.device) for k, v in encoding.items()}\n",
    "\n",
    "    # Set model to eval mode and predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "        logits = outputs.logits\n",
    "        predicted_id = logits.argmax(dim=-1).item()\n",
    "        confidence = torch.softmax(logits, dim=-1)[0][predicted_id].item()\n",
    "\n",
    "    # Convert to label\n",
    "    predicted_label = id2label[predicted_id]\n",
    "    return predicted_label, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac42b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example application\n",
    "\n",
    "text = \"Aspirin is known to reduce the risk of heart attacks.\"\n",
    "entity1 = \"Aspirin\"\n",
    "entity2 = \"heart attacks\"\n",
    "\n",
    "label, confidence = predict_relation(text, entity1, entity2, model, tokenizer, id2label)\n",
    "print(f\"Predicted relation: {label} (Confidence: {confidence:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
